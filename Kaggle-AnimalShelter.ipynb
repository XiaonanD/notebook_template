{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is Kaggle's AnimalShelter project: Help improve outcomes for shelter animals \n",
    "##https://www.kaggle.com/c/shelter-animal-outcomes\n",
    "# Brief description of this project: Using a dataset of intake information including breed, color, sex, and age \n",
    "# from the Austin Animal Center, we're asking Kagglers to predict the outcome for each animal(5 classes).\n",
    "###This is a multiclass classification problem and metric is logLoss(multi-class logarithmic loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, pipeline, metrics, grid_search, cross_validation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_train = { #'AnimalID': np.str_,\n",
    "         'Name': np.str_,\n",
    "         'DateTime': np.str_,\n",
    "         'AnimalType':np.str_,\n",
    "         'SexuponOutcome':np.str_,\n",
    "         'AgeuponOutcome':np.str_,\n",
    "         'Breed': np.str_,\n",
    "         'Color':np.str_,\n",
    "         'OutcomeSubtype': np.str_,\n",
    "         'OutcomeType':np.str_\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train is training set, labels are target value of training set\n",
    "train = pd.read_csv('train.csv',dtype = dtype_train, usecols= dtype_train)\n",
    "target = train['OutcomeType']\n",
    "labels = train['OutcomeType']\n",
    "train = train.drop(['OutcomeSubtype','OutcomeType'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test set\n",
    "dtype_test = { \n",
    "         'Name': np.str_,\n",
    "         'DateTime': np.str_,\n",
    "         'AnimalType':np.str_,\n",
    "         'SexuponOutcome':np.str_,\n",
    "         'AgeuponOutcome':np.str_,\n",
    "         'Breed': np.str_,\n",
    "         'Color':np.str_,    \n",
    "}\n",
    "test = pd.read_csv('test.csv',dtype = dtype_test,usecols= dtype_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatate training and test dataset together and call df_all\n",
    "df_all = pd.concat((train,test), axis = 0, ignore_index= True)\n",
    "df_all.shape\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_evaluation function and feature importance plot functions#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "\n",
    "#This is function to evalute models, scoring is 'log_loss'.\n",
    "def model_evaluation(X_train, y_train, clf, param_grid, cv):\n",
    "    model = GridSearchCV(estimator = clf,\n",
    "                         param_grid = param_grid,\n",
    "                         scoring = 'log_loss',\n",
    "                         cv = cv\n",
    "                         )\n",
    "    #fit model\n",
    "    model.fit(X_train,y_train)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters:\", model.best_params_)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to plot feature_importance.\n",
    "def plot_feature_importance(feature_importances,feature_names):\n",
    "    ftr_imp_df = pd.DataFrame(sorted(zip(feature_names,feature_importances)\n",
    "                          , key=lambda x: x[1], reverse = False)\n",
    "                   )\n",
    "    y_pos = np.arange(ftr_imp_df.shape[0])\n",
    "\n",
    "    plt.barh(y_pos, ftr_imp_df[1], align='center', alpha=0.4)\n",
    "    plt.yticks(y_pos, ftr_imp_df[0])\n",
    "    plt.xlabel('Feature Importance')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabelEncoder all features and target first as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_columns = ['Name',\n",
    " 'DateTime',\n",
    " 'AnimalType',\n",
    " 'SexuponOutcome',\n",
    " 'AgeuponOutcome',\n",
    " 'Breed',\n",
    " 'Color']\n",
    "\n",
    "#Since most of features are catergorical features,so firstly LabelEncoding all features.\n",
    "LBL = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in cat_columns:\n",
    "    print (\"encoding %s\"  %col)\n",
    "    df_all[col] = LBL.fit_transform(df_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Also Label encoding target. print target value and its corresponding assigned number.\n",
    "LBL.fit(labels)\n",
    "\n",
    "tgt_cls = dict(zip(labels.unique()\n",
    "               , LBL.transform(labels.unique())))\n",
    "\n",
    "print (\"Target encoded as : \", tgt_cls)\n",
    "labels = LBL.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('Target encoded as : ', {'Transfer': 4, 'Adoption': 0, 'Return_to_owner': 3, 'Died': 1, 'Euthanasia': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering: 1) datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get original 'DateTime' from train+test\n",
    "a = pd.concat([train['DateTime'],test['DateTime']],axis =0,ignore_index= True)\n",
    "df_all['DateTime'] = a\n",
    "\n",
    "df_all['DateTime']=pd.to_datetime(df_all['DateTime'],infer_datetime_format = True, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get 7 new features, year, month, day, quater and weekday\n",
    "df_all['year'] = df_all['DateTime'].dt.year\n",
    "df_all['month'] = df_all['DateTime'].dt.month\n",
    "df_all['day'] = df_all['DateTime'].dt.day\n",
    "df_all['quarter'] = df_all['DateTime'].dt.quarter\n",
    "df_all['weekday'] = df_all['DateTime'].dt.weekday\n",
    "df_all['hour'] = df_all['DateTime'].dt.hour\n",
    "df_all['weekOfYear'] = df_all['DateTime'].dt.weekofyear\n",
    "\n",
    "##Remove the old feature\n",
    "df_all = df_all.drop('DateTime',axis =1)\n",
    "# quarter --1: Jan-Mar; 2:Apr-June; 3:July-Sept; 4:Oct-Dec\n",
    "# weekday-- 0:Mon; 1:Tue...5:Saturday,6:Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot them time-related features and see their relationship\n",
    "fig = plt.figure(figsize=(18,8))\n",
    "plt.subplot(221)\n",
    "plt.hist(df_all.year,bins=10,normed=True)\n",
    "plt.title('search by year')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(df_all.hour,range(25),normed=True)\n",
    "plt.title('search by hour')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(df_all.weekday,range(-1,9),normed=True)\n",
    "plt.title('search by weekday')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.hist(df_all.month,range(-1,14),normed=True)\n",
    "plt.title('search by month')\n",
    "# weekday-- 0:Mon; 1:Tue...5:Saturday,6:Sunday\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering: 2) AgeuponOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# year/years, weeks, month/months, days/day, NaN\n",
    "# Put AgeuponOutcome feature into numbers of years.\n",
    "def cal_age_in_years(x):\n",
    "    x = str(x)\n",
    "    if x =='nan': \n",
    "        return 0\n",
    "    age = int(x.split()[0])\n",
    "    if 'year' in x:\n",
    "        return age\n",
    "    if 'month' in x:\n",
    "        return age/12.\n",
    "    if 'day' in x:\n",
    "        return age/365.\n",
    "    else: \n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Get original 'AgeuponOutcome'\n",
    "a = pd.concat([train['AgeuponOutcome'],test['AgeuponOutcome']],axis =0, ignore_index = True)\n",
    "df_all['AgeuponOutcome'] = a\n",
    "\n",
    "## Apply cal_age_in_years and change to number of years.\n",
    "df_all['AgeuponOutcome']=df_all['AgeuponOutcome'].apply(cal_age_in_years)\n",
    "\n",
    "\n",
    "#Add noise to Age *np.random.uniform(0.95,1.05), this is critical to avoid overfitting and make model robust.\n",
    "mid_piv = train.shape[0]\n",
    "df_all.AgeuponOutcome[:mid_piv] = df_all.AgeuponOutcome[:mid_piv]* np.random.uniform(0.95,1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering --3) Length of name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.concat([train['Name'],test['Name']],axis =0, ignore_index = True)\n",
    "\n",
    "df_all['LengthofName'] = a.apply(lambda row: len(str(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Engineering 4) SexuponOutcomeÂ¶\n",
    "\n",
    "###There are two information here: 1) Sex: female or male 2) Neutered/Spayed or intact\n",
    "\n",
    "Now try to separate these two pieces of information. And see if it can imporve the score\n",
    "\n",
    "---No, it doesn't help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering 5) Breed \n",
    "\n",
    "This is a catergorical feature with high cardinality.\n",
    "I used \"leave-one-out\" method(Owen Zhang's method) to engineer this feature.\n",
    "But from CV score and LB score, it doesn't help. Finally I decided not to engineer this feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting-tuning hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest as a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "History:\n",
    "#1) 'max_features' :'sqrt' (the best)\n",
    "#2) with verbose =5 (picking from 5,10)) it seems verbose is not very important, so just use default number\n",
    "\n",
    "#2) By trying previously, the larger n_estimator, the better model(score) it is. \n",
    "# Therefore, directly use n_estimator = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#choose a model\n",
    "rf = RandomForestClassifier(n_estimators= 500, random_state= 1234, criterion='gini')\n",
    "clf = rf\n",
    "\n",
    "## Assign train_X, y_train\n",
    "mid_piv = train.shape[0]\n",
    "X = df_all[:mid_piv]\n",
    "y = labels\n",
    "\n",
    "#####model fitting\n",
    "\n",
    "start = time()\n",
    "\n",
    "param_grid = {'n_estimators':[2500]\n",
    "             , 'random_state' : [1234]}\n",
    "\n",
    "model = model_evaluation(X,y,clf,param_grid, 5)\n",
    "\n",
    "print(\"this takes %.2f seconds\" %(time()-start)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf2500 = RandomForestClassifier(n_estimators= 2500, random_state= 1234, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot feature importance in rf\n",
    "feature_names = df_all.columns\n",
    "plot_feature_importance(model.best_estimator_.feature_importances_,feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final extraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_extraTree = ExtraTreesClassifier(n_estimators= 1000, random_state= 1234, criterion='gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After tune learning_rate, max_depth, min_child_weight, subsample, colsample_bytree, reg_lambda, n_estimator\n",
    "#Below is the model and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model_xgb= xgb.XGBClassifier(max_depth=9, learning_rate=0.01, n_estimators=1433, silent=False, \n",
    "                      objective='multi:softprob', nthread=-1, gamma=0.3, min_child_weight=3, subsample=0.9, \n",
    "                      colsample_bytree=0.5,  reg_lambda=1, seed=1234, missing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble-blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mid_piv = train.shape[0]\n",
    "X = df_all[:mid_piv].values\n",
    "y = labels.reshape(mid_piv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model ensemble code: Here three models are used and Each model will do get a probability(5 columns) prediction. \n",
    "    \n",
    "And those predtions will be stored into train_blend_x and will be used as next layters' predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "num_class = 5 # y has five different classes: Adoption, Transfer...\n",
    "n_folds = 3\n",
    "\n",
    "(train_x, train_y, test_x) = (X\n",
    "                        ,y\n",
    "                        ,df_all[mid_piv:].values)\n",
    "\n",
    "skf = list(StratifiedKFold(train_y, n_folds))\n",
    "\n",
    "\n",
    "clfs = [\n",
    "        model_xgb,\n",
    "        model_rf2500,\n",
    "        model_extraTree\n",
    "       ]\n",
    "\n",
    "print \"Creating train and test sets for blending.\"\n",
    "\n",
    "train_blend_x = np.zeros((train_x.shape[0], len(clfs)*num_class))\n",
    "test_blend_x = np.zeros((test_x.shape[0], len(clfs)*num_class))\n",
    "scores = np.zeros ((len(skf),len(clfs)))\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    print (\"Blending model\",j, clf)\n",
    "    test_blend_x_j = np.zeros((test_x.shape[0], num_class))\n",
    "    for i, (train, val) in enumerate(skf):\n",
    "        print (\"Model %d fold %d\" %(j,i))\n",
    "        train_x_fold = train_x[train]\n",
    "        train_y_fold = train_y[train]\n",
    "        val_x_fold = train_x[val]\n",
    "        val_y_fold = train_y[val]\n",
    "        clf.fit(train_x_fold, train_y_fold)\n",
    "        val_y_predict_fold = clf.predict_proba(val_x_fold)\n",
    "        score = metrics.log_loss(val_y_fold,val_y_predict_fold)\n",
    "        print (\"LOGLOSS: \", score)\n",
    "        scores[i,j]=score\n",
    "        train_blend_x[val, j*num_class:j*num_class+num_class] = val_y_predict_fold\n",
    "        test_blend_x_j = test_blend_x_j + clf.predict_proba(test_x)\n",
    "    test_blend_x[:,j*num_class:j*num_class+num_class] = test_blend_x_j/len(skf)\n",
    "    print (\"Score for model %d is %f\" % (j,np.mean(scores[:,j])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation/ Grid Search with blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here for 2nd layer stacking, LogisticRegression is used.\n",
    "# In this layer, the input is the ouput of first layer, and target is still the orginal target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print  (\"Blending.\")\n",
    "param_grid = {\n",
    "              }\n",
    "model = model_evaluation(train_blend_x\n",
    "                                         , train_y\n",
    "                                         , LogisticRegression()\n",
    "                                         , param_grid\n",
    "                                         , cv=5\n",
    "                                         )   \n",
    "\n",
    "print (\"best params:\", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(test_blend_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[['Adoption','Died','Euthanasia','Return_to_owner','Transfer']] = prediction\n",
    "submission.to_csv('Final-blending.csv',index = False)\n",
    "print ('job done. csv ready in your expedia folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final sumbmission\n",
    "#1) submit-Final1-xgb-nobreed.csv --LB: 0.71780, CV score: -0.735\n",
    "#2) Final-blending1-3models.csv --LB: 0.73370, CV score: -0.756\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
