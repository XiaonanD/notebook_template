{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/bertcarremans/TwitterUSAirlineSentiment/blob/master/source/Predicting%20sentiment%20with%20text%20features.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import emoji\n",
    "from pprint import pprint\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import gensim\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df = df[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>@united WHERE IS MY RECEIPT! I upgraded return...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>@AmericanAir you should be contacting her for ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>@united anything yet JJ?</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>.@united: Just landed. A day Late Flight with ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>@JetBlue Airways Reveals 'Bluemanity' Livery -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "1277   @united WHERE IS MY RECEIPT! I upgraded return...          negative\n",
       "14167  @AmericanAir you should be contacting her for ...           neutral\n",
       "2875                            @united anything yet JJ?           neutral\n",
       "3865   .@united: Just landed. A day Late Flight with ...          negative\n",
       "8432   @JetBlue Airways Reveals 'Bluemanity' Livery -...          positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Text variable\n",
    "To analyze the text variable we create a class **TextCounts**. In this class we compute some basic statistics on the text variable. This class can be used later in a Pipeline, as well.\n",
    "\n",
    "* **count_words** : number of words in the tweet\n",
    "* **count_mentions** : referrals to other Twitter accounts, which are preceded by a @\n",
    "* **count_hashtags** : number of tag words, preceded by a #\n",
    "* **count_capital_words** : number of uppercase words, could be used to *\"shout\"* and express (negative) emotions\n",
    "* **count_excl_quest_marks** : number of question or exclamation marks\n",
    "* **count_urls** : number of links in the tweet, preceded by http(s)\n",
    "* **count_emojis** : number of emoji, which might be a good indication of the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounts(BaseEstimator, TransformerMixin):\n",
    "    def count_regex(self, pattern, text):\n",
    "        return len(re.findall(pattern, text))\n",
    "    \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        # fit method is used when specific operations need to be done on the train data, but not on the test data\n",
    "        return self\n",
    "    \n",
    "    # X here is a pd.Series not a pd.DataFrame\n",
    "    def transform(self, X, **transform_params):\n",
    "        count_words = X.apply(lambda x: self.count_regex(r'\\w+', x)) \n",
    "        count_mentions = X.apply(lambda x: self.count_regex(r'@\\w+', x))\n",
    "        count_hashtags = X.apply(lambda x: self.count_regex(r'#\\w+', x))\n",
    "        count_capital_words = X.apply(lambda x: self.count_regex(r'\\b[A-Z]{2,}\\b', x))\n",
    "        count_excl_quest_marks = X.apply(lambda x: self.count_regex(r'!|\\?', x))\n",
    "        count_urls = X.apply(lambda x: self.count_regex(r'http.?://[^\\s]+[\\s]?', x))\n",
    "        # We will replace the emoji symbols with a description, which makes using a regex for counting easier\n",
    "        # Moreover, it will result in having more words in the tweet\n",
    "        count_emojis = X.apply(lambda x: emoji.demojize(x)).apply(lambda x: self.count_regex(r':[a-z_&]+:', x))\n",
    "        \n",
    "        df = pd.DataFrame({'count_words': count_words\n",
    "                           , 'count_mentions': count_mentions\n",
    "                           , 'count_hashtags': count_hashtags\n",
    "                           , 'count_capital_words': count_capital_words\n",
    "                           , 'count_excl_quest_marks': count_excl_quest_marks\n",
    "                           , 'count_urls': count_urls\n",
    "                           , 'count_emojis': count_emojis\n",
    "                          })\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCounts()\n",
    "df_eda = tc.fit_transform(df.text)\n",
    "# Add airline_sentiment to df_eda\n",
    "df_eda['airline_sentiment'] = df.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "1277            21               1               0                    5   \n",
       "14167           17               1               0                    0   \n",
       "2875             4               1               0                    1   \n",
       "3865            28               1               0                    0   \n",
       "\n",
       "       count_excl_quest_marks  count_urls  count_emojis airline_sentiment  \n",
       "1277                        2           1             0          negative  \n",
       "14167                       0           0             0           neutral  \n",
       "2875                        1           0             0           neutral  \n",
       "3865                        0           0             0          negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eda.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be interesting to see how the TextStats variables relate to the class variable. Therefore we write a function **show_dist** that provides descriptive statistics and a plot per target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dist(df, col):\n",
    "    print('Descriptive stats for {}'.format(col))\n",
    "    print('-'*(len(col)+22))\n",
    "    print(df.groupby('airline_sentiment')[col].describe())\n",
    "    bins = np.arange(df[col].min(), df[col].max() + 1)\n",
    "    g = sns.FacetGrid(df, col='airline_sentiment', hue='airline_sentiment', palette=\"PuBuGn_d\")\n",
    "    g = g.map(sns.distplot, col, kde=False, norm_hist=True, bins=bins)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive stats for count_mentions\n",
      "------------------------------------\n",
      "                    count      mean       std  min  25%  50%  75%  max\n",
      "airline_sentiment                                                     \n",
      "negative           9178.0  1.111244  0.365420  1.0  1.0  1.0  1.0  6.0\n",
      "neutral            3099.0  1.167473  0.480102  1.0  1.0  1.0  1.0  5.0\n",
      "positive           2363.0  1.138383  0.432462  1.0  1.0  1.0  1.0  6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_dist(df_eda,'count_mentions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSIONS: **\n",
    "* **The number of words** used in the tweets is rater low. Maximum number of words is 36 and there are even tweets with only 2 words. So we'll have to be careful during data cleaning not to remove too many words. On the other hand, the text processing will be faster. Negative tweets contain more words than neutral or positive tweets.\n",
    "* All tweets have at least one **mention**. Probably this is the result of extracting the tweets based on mentions in the Twitter data. There seems to be no difference in number of mentions with regard to the sentiment.\n",
    "* Most of the tweets do not contain **hash tags**. So probably this variable will not be retained during model training. Again, no difference in number of hash tags with regard to the sentiment.\n",
    "* Most of the tweets do not contain **capitalized words** and we do not see a difference in distribution between the sentiments.\n",
    "* The positive tweets seem to be using a bit more **exclamation or question marks**.\n",
    "* Most tweets do not contain a **URL**. \n",
    "* Most tweets do not use **emojis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning\n",
    "Before we start using the tweets' text we clean it. We'll do the this in the class CleanText:\n",
    "- remove the **mentions**, as we want to make the model generalisable to tweets of other airline companies too.\n",
    "- remove the **hash tag sign** (#) but not the actual tag as this may contain information\n",
    "- set all words to **lowercase**\n",
    "- remove all **punctuations**, including the question and exclamation marks\n",
    "- remove the **urls** as they do not contain useful information and we did not notice a distinction in the number of urls used between the sentiment classes\n",
    "- make sure the converted **emojis** are kept as one word. \n",
    "- remove **digits**\n",
    "- remove **stopwords**\n",
    "- apply the **PorterStemmer** to keep the stem of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "\n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    # X is a pd.Series not pd.DataFrame\n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions)\\\n",
    "                   .apply(self.remove_urls)\\\n",
    "                   .apply(self.emoji_oneword)\\\n",
    "                   .apply(self.remove_punctuation)\\\n",
    "                   .apply(self.remove_digits).apply(self.to_lower)\\\n",
    "                   .apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return clean_X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10620                                  told work joke fail\n",
       "13609    aa usair elit member one big disappoint way tr...\n",
       "2955        bummer might go card instead ty respons though\n",
       "3585     well incom flight dca take us ewr delay made u...\n",
       "2087     tri chang flight three time phone got disconne...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CleanText()\n",
    "sr_clean = ct.fit_transform(df.text)\n",
    "sr_clean[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sr_clean == ''\n",
    "print('there are {} records with no words after cleaning'.format(mask.sum()))\n",
    "sr_clean.loc[mask] = '[no_text]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10620    @USAirways told to work it out ourselves #joke...\n",
       "13609    @AmericanAir that all AA is for USAir Elite me...\n",
       "2955     @united Bummer. Might have to go with @America...\n",
       "3585     @united well the income flight to dca to take ...\n",
       "2087     @united we have tried to change our flight THR...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: **One side-effect of text cleaning is that some rows do not have any words left in their text. For the CountVectorizer and TfIdfVectorizer this does not really pose a problem. However, for the Word2Vec algorithm this causes an error. There are different strategies that you could apply to deal with these missing values.\n",
    "\n",
    "* Remove the complete row, but in a production environment this is not really desirable.\n",
    "* Impute the missing value with some placeholder text like *[no_text]*\n",
    "* Word2Vec: use the average of all vectors\n",
    "\n",
    "Here we will impute with a placeholder text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 22 records with no words after cleaning\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the cleaned text of the tweets, we can have a look at what are the most frequent words. Below we'll show the top 20 words. \n",
    "\n",
    "**CONCLUSION: **Not surprisingly the most frequent word is *flight*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "count_sr_clean = cv.fit_transform(sr_clean).toarray()\n",
    "\n",
    "count_sr_clean = pd.DataFrame({'counts': count_sr_clean.sum(axis = 0)\n",
    "                               ,'word': cv.get_feature_names()\n",
    "                              })\n",
    "top_20 = count_sr_clean.sort_values(by = 'counts', ascending= False ).head(20)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.barplot(data = top_20 , x = 'word', y = 'counts', palette= \"PuBuGn_d\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get final dataset\n",
    "\n",
    "First we combine the TextCounts variables with the CleanText variable.\n",
    "\n",
    "**NOTE: **Initially, I made the mistake to do execute TextCounts and CleanText in the GridSearchCV below. This took too long as it applies these functions each run of the GridSearch. It suffices to run them only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_words',\n",
       " 'count_mentions',\n",
       " 'count_hashtags',\n",
       " 'count_capital_words',\n",
       " 'count_excl_quest_marks',\n",
       " 'count_urls',\n",
       " 'count_emojis',\n",
       " 'airline_sentiment',\n",
       " 'clean_text']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df_eda\n",
    "df_model['clean_text'] = sr_clean\n",
    "df_model.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_mentions</th>\n",
       "      <th>count_hashtags</th>\n",
       "      <th>count_capital_words</th>\n",
       "      <th>count_excl_quest_marks</th>\n",
       "      <th>count_urls</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>receipt upgrad return leg month late flightr s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>contact refund dm provid phone number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anyth yet jj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_words  count_mentions  count_hashtags  count_capital_words  \\\n",
       "1277            21               1               0                    5   \n",
       "14167           17               1               0                    0   \n",
       "2875             4               1               0                    1   \n",
       "\n",
       "       count_excl_quest_marks  count_urls  count_emojis airline_sentiment  \\\n",
       "1277                        2           1             0          negative   \n",
       "14167                       0           0             0           neutral   \n",
       "2875                        1           0             0           neutral   \n",
       "\n",
       "                                              clean_text  \n",
       "1277   receipt upgrad return leg month late flightr s...  \n",
       "14167              contact refund dm provid phone number  \n",
       "2875                                        anyth yet jj  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So df_model now contains several variables. However, our vectorizers (see below) will only need the *clean_text* variable. The TextCounts variables can be added as such. To specifically select columns, I wrote the class **ColumnExtractor** below. This can be used in the Pipeline afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning and cross-validation\n",
    "As we will see below, the vectorizers and classifiers all have configurable parameters. In order to chose the best parameters, we need to evaluate on a separate validation set that was not used during the training. However, using only one validation set may not produce reliable validation results. Due to chance you might have a good model performance on the validation set. If you would split the data otherwise, you might end up with other results. To get a more accurate estimation, we perform **cross-validation**. \n",
    "\n",
    "With cross-validation the data is split into a train and validation set multiple times. The evaluation metric is then averaged over the different folds. Luckily, GridSearchCV applies cross-validation out-of-the-box.\n",
    "\n",
    "To find the best parameters for both a vectorizer and classifier, we create a **Pipeline**. All this is put into a function for ease of use.\n",
    "\n",
    "### Evaluation metrics\n",
    "By default GridSearchCV uses the default scorer to compute the *best_score_*. For both the MultiNomialNb and LogisticRegression this default scoring metric is the accuracy. \n",
    "\n",
    "In our function *grid_vect* we additionally generate the *classification_report* on the test data. This provides some interesting metrics **per target class**, which might be more appropriate here. These metrics are the **precision, recal and F1 score.**\n",
    "\n",
    "* **Precision: ** Of all rows we predicted to be a certain class, how many did we correctly predict?\n",
    "* **Recall: ** Of all rows of a certain class, how many did we correctly predict?\n",
    "* **F1 score: ** Harmonic mean of Precision and Recall.\n",
    "\n",
    "Precision and Recall can be calculated with the elements of the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment, test_size=0.1, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "     \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, parameters_text=None, vect=None):\n",
    "    \"\"\"\n",
    "    build the pipeline (counts + texts)-> clf\n",
    "    \"\"\"\n",
    "    textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                      ,'count_mentions','count_urls','count_words']\n",
    "    \n",
    "    counts_steps = [('counts_col', ColumnExtractor(textcountscols))\n",
    "                  ,('scaler', MinMaxScaler())]\n",
    "    counts_pipe = Pipeline(counts_steps)\n",
    "    \n",
    "    texts_steps = [('text_col', ColumnExtractor(cols ='clean_text')) #shouldn't use ['clean_text']\n",
    "                  ,('vect', vect)]\n",
    "    texts_pipe = Pipeline(texts_steps)\n",
    "    \n",
    "    features = FeatureUnion([('counts', counts_pipe),\n",
    "                            ('texts', texts_pipe)])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('features', features),\n",
    "    ('clf', clf)\n",
    "     ])\n",
    "    \n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "        \n",
    "    parameters.update(parameters_clf)\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=3)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    \n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print('')\n",
    "    \n",
    "    print('best CV score %.3f'%(grid_search.best_score_))\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__texts__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__texts__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__texts__vect__min_df': (1,2)\n",
    "}\n",
    "\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "\n",
    "\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_logreg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "Here we will compare the performance of a MultinomailNB and LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "To use words in a classifier, we need to convert the words to numbers. This can be done with a CountVectorizer. Sklearn's **CountVectorizer** takes all words in all tweets, assigns an ID and counts the frequency of the word per tweet. This *bag of words* can then be used as input for a classifier. It is what is called a **sparse** data set, meaning that each record will have many zeroes for the words not occurring in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__min_df': (1, 2),\n",
      " 'features__texts__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   21.9s finished\n",
      "/Users/xduan/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 22.472s\n",
      "\n",
      "best CV score 0.770\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__texts__vect__max_df: 0.25\n",
      "\tfeatures__texts__vect__min_df: 1\n",
      "\tfeatures__texts__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.785\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.95      0.87       925\n",
      "     neutral       0.72      0.42      0.53       331\n",
      "    positive       0.78      0.64      0.71       208\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1464\n",
      "   macro avg       0.77      0.67      0.70      1464\n",
      "weighted avg       0.78      0.78      0.77      1464\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_mnb_countvect.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_mnb_countvect, 'best_mnb_countvect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__texts__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__min_df': (1, 2),\n",
      " 'features__texts__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:   57.1s finished\n",
      "/Users/xduan/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 58.212s\n",
      "\n",
      "best CV score 0.792\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__texts__vect__max_df: 0.5\n",
      "\tfeatures__texts__vect__min_df: 1\n",
      "\tfeatures__texts__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.811\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.93      0.88       911\n",
      "     neutral       0.74      0.54      0.62       320\n",
      "    positive       0.79      0.73      0.76       233\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1464\n",
      "   macro avg       0.79      0.73      0.75      1464\n",
      "weighted avg       0.80      0.81      0.80      1464\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_logreg_countvect.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "# LogisticRegression\n",
    "best_logreg_countvect = grid_vect(logreg, parameters_logreg, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, 'best_logreg_countvect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_logreg_countvect_pickle.pkl', 'wb') as p:\n",
    "    pickle.dump(best_logreg_countvect, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "One issue with CountVectorizer is that there might be words that occur frequently in observations of the target classes. These words do not have discriminatory information and can be removed. [TF-IDF (term frequency - inverse document frequency)](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) can be used to downweight these frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__min_df': (1, 2),\n",
      " 'features__texts__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   23.0s finished\n",
      "/Users/xduan/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 23.514s\n",
      "\n",
      "best CV score 0.752\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__texts__vect__max_df: 0.25\n",
      "\tfeatures__texts__vect__min_df: 2\n",
      "\tfeatures__texts__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.763\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.97      0.85       925\n",
      "     neutral       0.75      0.35      0.48       331\n",
      "    positive       0.85      0.51      0.64       208\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1464\n",
      "   macro avg       0.79      0.61      0.65      1464\n",
      "weighted avg       0.77      0.76      0.73      1464\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_mnb_tfidf.pkl']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "best_mnb_tfidf = grid_vect(mnb, parameters_mnb, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "joblib.dump(best_mnb_tfidf, 'best_mnb_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__texts__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__texts__vect__min_df': (1, 2),\n",
      " 'features__texts__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:   52.0s finished\n",
      "/Users/xduan/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 52.291s\n",
      "\n",
      "best CV score 0.786\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__texts__vect__max_df: 0.25\n",
      "\tfeatures__texts__vect__min_df: 2\n",
      "\tfeatures__texts__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.808\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.95      0.88       925\n",
      "     neutral       0.75      0.56      0.64       331\n",
      "    positive       0.76      0.58      0.66       208\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1464\n",
      "   macro avg       0.78      0.70      0.73      1464\n",
      "weighted avg       0.80      0.81      0.80      1464\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_logreg_tfidf.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "best_logreg_tfidf = grid_vect(logreg, parameters_logreg, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "joblib.dump(best_logreg_tfidf, 'best_logreg_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "* Both classifiers achieve the best results when using the features of the CountVectorizer\n",
    "* Overall, Logistic Regression outperforms the Multinomial Naive Bayes classifier\n",
    "* The best performance on the test set comes from the LogisticRegression with features from CountVectorizer. \n",
    "\n",
    "Best parameters:\n",
    "* C value of 1\n",
    "* L2 regularization\n",
    "* max_df: 0.5 or maximum document frequency of 50%.\n",
    "* min_df: 1 or the words need to appear in at least 2 tweets\n",
    "* ngram_range: (1, 2), both single words as bi-grams are used\n",
    "\n",
    "Evaluation metrics:\n",
    "* A **test accuracy** of 81,3%, which is better than what we would achieve by setting the prediction for all observations to the majority class (*negative* which would give 63% accuracy).\n",
    "* The **Precision** is rather high for all three classes. For instance, of all cases that we predict as negative, 80% is indeed negative.\n",
    "* The **Recall** for the neutral class is low. Of all neutral cases in our test data, we only predict 48% as being neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xduan/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "textcountscols = ['count_capital_words','count_emojis','count_excl_quest_marks','count_hashtags'\n",
    "                  ,'count_mentions','count_urls','count_words']\n",
    "\n",
    "counts_steps = [('counts_col', ColumnExtractor(textcountscols))\n",
    "              ,('scaler', MinMaxScaler())]\n",
    "counts_pipe = Pipeline(counts_steps)\n",
    "\n",
    "texts_steps = [('text_col', ColumnExtractor(cols ='clean_text')) #shouldn't use ['clean_text']\n",
    "              ,('vect', CountVectorizer(max_df=0.5, min_df=2, ngram_range=(1,2)))]\n",
    "texts_pipe = Pipeline(texts_steps)\n",
    "\n",
    "features = FeatureUnion([('counts', counts_pipe),\n",
    "                        ('texts', texts_pipe)])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "('features', features),\n",
    "('clf', LogisticRegression(C=0.5, penalty='l2'))\n",
    " ])\n",
    "\n",
    "best_model = pipeline.fit(df_model.drop('airline_sentiment', axis=1), df_model.airline_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positive_tweets = pd.Series([\"Thank you @VirginAmerica for you amazing customer support team on Tuesday 11/28 at @EWRairport and returning my lost bag in less than 24h! #efficiencyiskey #virginamerica\"\n",
    "                      ,\"Love flying with you guys ask these years.  Sad that this will be the last trip 😂   @VirginAmerica  #LuxuryTravel\"\n",
    "                      ,\"Wow @VirginAmerica main cabin select is the way to fly!! This plane is nice and clean & I have tons of legroom! Wahoo! NYC bound! ✈️\"])\n",
    "\n",
    "df_counts_pos = tc.transform(new_positive_tweets)\n",
    "df_clean_pos = ct.transform(new_positive_tweets)\n",
    "df_model_pos = df_counts_pos\n",
    "df_model_pos['clean_text'] = df_clean_pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the model\n",
    "pipe = best_model\n",
    "\n",
    "dump_path = 'best_pickle.pkl'\n",
    "\n",
    "with open(dump_path, 'wb') as p:\n",
    "    pickle.dump(pipe, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "dump_path = 'best_pickle.pkl'\n",
    "# loaded_pipeline = pickle.load(open)\n",
    "with open(dump_path, 'rb') as p:\n",
    "    pickle_pipeline = pickle.load(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_pipeline.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load previous trained model in GridSearch and it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "dump_path = 'best_logreg_countvect_pickle.pkl'\n",
    "# loaded_pipeline = pickle.load(open)\n",
    "with open(dump_path, 'rb') as p:\n",
    "    pickle_pipeline = pickle.load(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('best_logreg_countvect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_positive_tweets = pd.Series([\"Thank you @VirginAmerica for you amazing customer support team on Tuesday 11/28 at @EWRairport and returning my lost bag in less than 24h! #efficiencyiskey #virginamerica\"\n",
    "                      ,\"Love flying with you guys ask these years.  Sad that this will be the last trip 😂   @VirginAmerica  #LuxuryTravel\"\n",
    "                      ,\"Wow @VirginAmerica main cabin select is the way to fly!! This plane is nice and clean & I have tons of legroom! Wahoo! NYC bound! ✈️\"])\n",
    "\n",
    "df_counts_pos = tc.transform(new_positive_tweets)\n",
    "df_clean_pos = ct.transform(new_positive_tweets)\n",
    "df_model_pos = df_counts_pos\n",
    "df_model_pos['clean_text'] = df_clean_pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'positive', 'negative']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_pipeline.predict(df_model_pos).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_negative_tweets = pd.Series([\"@VirginAmerica shocked my initially with the service, but then went on to shock me further with no response to what my complaint was. #unacceptable @Delta @richardbranson\"\n",
    "                      ,\"@VirginAmerica this morning I was forced to repack a suitcase w a medical device because it was barely overweight - wasn't even given an option to pay extra. My spouses suitcase then burst at the seam with the added device and had to be taped shut. Awful experience so far!\"\n",
    "                      ,\"Board airplane home. Computer issue. Get off plane, traverse airport to gate on opp side. Get on new plane hour later. Plane too heavy. 8 volunteers get off plane. Ohhh the adventure of travel ✈️ @VirginAmerica\"])\n",
    "\n",
    "df_counts_neg = tc.transform(new_negative_tweets)\n",
    "df_clean_neg = ct.transform(new_negative_tweets)\n",
    "df_model_neg = df_counts_neg\n",
    "df_model_neg['clean_text'] = df_clean_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'negative', 'negative']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_model_neg).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'negative', 'negative']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_pipeline.predict(df_model_neg).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py\n",
    "Try scoring='neg_log_loss'\n",
    "neg_log_loss_scorer = make_scorer(log_loss, greater_is_better=False,\n",
    "                                  needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss:\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
